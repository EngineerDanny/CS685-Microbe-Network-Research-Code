{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotnine as p9\n",
    "import plotnine.options as p9options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_results_dir = \"/projects/genomic-ml/da2343/ml_project_1/algo_comparison/results\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_error_graph(error_df, categories=None, name=\"test_error_graph\"):\n",
    "    # Get unique values as list from column name `Dataset`\n",
    "    dataset_list = error_df[\"Dataset\"].unique().tolist()\n",
    "    # colors = [\"#000080\", \"#FF8000\", \"#800080\", \"#8B0000\", \"#D3D3D3\"]\n",
    "    colors = [\"orange\", \"#67001f\", \"#053061\", \"blue\", \"red\"]\n",
    "\n",
    "    test_error_df_list = []\n",
    "\n",
    "    for dataset in dataset_list:\n",
    "        # remove multi\n",
    "        # Get new dataframe with only the dataset\n",
    "        sub_dataset_df = error_df[error_df[\"Dataset\"] == dataset]\n",
    "        n_samples_list = sub_dataset_df[\"# of Total Samples\"].unique().tolist()\n",
    "\n",
    "        for n_sample in n_samples_list:\n",
    "            filtered_csv = sub_dataset_df[\n",
    "                sub_dataset_df[\"# of Total Samples\"] == n_sample\n",
    "            ]\n",
    "            algo_list = filtered_csv[\"Algorithm\"].unique().tolist()\n",
    "\n",
    "            for algorithm in algo_list:\n",
    "                sub_filtered_csv = filtered_csv[filtered_csv[\"Algorithm\"] == algorithm]\n",
    "                # Get new dataframe with only the dataset and n_sample\n",
    "                mean_mse = sub_filtered_csv[\"Mean Squared Error\"].mean()\n",
    "                std_mse = sub_filtered_csv[\"Mean Squared Error\"].std() * 0.02\n",
    "                # std_mse = sub_filtered_csv['Mean Squared Error'].std() * 0.01\n",
    "                mse_min = mean_mse - std_mse\n",
    "                mse_max = mean_mse + std_mse\n",
    "\n",
    "                test_error_dict = {\n",
    "                    \"# of Total Samples\": n_sample,\n",
    "                    \"Mean Squared Error\": mean_mse,\n",
    "                    \"ymin\": mse_min,\n",
    "                    \"ymax\": mse_max,\n",
    "                    \"Dataset\": dataset,\n",
    "                    \"Algorithm\": algorithm,\n",
    "                }\n",
    "                test_error_df_list.append(pd.DataFrame(test_error_dict, index=[0]))\n",
    "    my_combined_results_df = pd.concat(test_error_df_list).reset_index()\n",
    "    if categories is not None:\n",
    "        my_combined_results_df[\"Dataset\"] = pd.Categorical(\n",
    "            my_combined_results_df[\"Dataset\"],\n",
    "            categories=categories,\n",
    "            ordered=True,\n",
    "        )\n",
    "\n",
    "    gg = (\n",
    "        p9.ggplot(my_combined_results_df)\n",
    "        + p9.aes(\n",
    "            x=\"# of Total Samples\",\n",
    "            y=\"Mean Squared Error\",\n",
    "            ymin=\"ymin\",\n",
    "            ymax=\"ymax\",\n",
    "            fill=\"Algorithm\",\n",
    "        )\n",
    "        + p9.facet_wrap(\"~Dataset\", scales=\"free_x\")\n",
    "        + p9.geom_line(p9.aes(color=\"Algorithm\"))\n",
    "        + p9.geom_ribbon(alpha=0.3)\n",
    "        + p9.scale_x_continuous(breaks=n_samples_list)\n",
    "        + p9.scale_fill_manual(\n",
    "            breaks=[\"Featureless\", \"Spearman\", \"Pearson\", \"LASSO\", \"GGM\"], values=colors\n",
    "        )\n",
    "        + p9.scale_color_manual(\n",
    "            breaks=[\"Featureless\", \"Spearman\", \"Pearson\", \"LASSO\", \"GGM\"], values=colors\n",
    "        )\n",
    "        + p9.xlab(\"# of Total Samples\")\n",
    "    )\n",
    "    # show the plot\n",
    "    print(gg)\n",
    "    # TODO: Uncomment to save the plot\n",
    "    gg.save(f\"{name}.png\", dpi=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_error_df(error_df):\n",
    "    dataset_list = error_df[\"Dataset\"].unique().tolist()\n",
    "\n",
    "    for dataset in dataset_list:\n",
    "        test_error_df_list = []\n",
    "        # Get new dataframe with only the dataset\n",
    "        sub_dataset_df = error_df[error_df[\"Dataset\"] == dataset]\n",
    "        n_samples_list = sub_dataset_df[\"# of Total Samples\"].unique().tolist()\n",
    "\n",
    "        for n_sample in n_samples_list:\n",
    "            filtered_csv = sub_dataset_df[\n",
    "                sub_dataset_df[\"# of Total Samples\"] == n_sample\n",
    "            ]\n",
    "            algo_list = filtered_csv[\"Algorithm\"].unique().tolist()\n",
    "\n",
    "            for algorithm in algo_list:\n",
    "                sub_filtered_csv = filtered_csv[filtered_csv[\"Algorithm\"] == algorithm]\n",
    "                # Get new dataframe with only the dataset and n_sample\n",
    "                mean_mse = sub_filtered_csv[\"Mean Squared Error\"].mean()\n",
    "                std_mse = sub_filtered_csv[\"Mean Squared Error\"].std() * 0.02\n",
    "                # std_mse = sub_filtered_csv['Mean Squared Error'].std() * 0.01\n",
    "                mse_min = mean_mse - std_mse\n",
    "                mse_max = mean_mse + std_mse\n",
    "\n",
    "                test_error_dict = {\n",
    "                    \"# of Total Samples\": n_sample,\n",
    "                    \"Mean Squared Error\": mean_mse,\n",
    "                    \"ymin\": mse_min,\n",
    "                    \"ymax\": mse_max,\n",
    "                    \"Dataset\": dataset,\n",
    "                    \"Algorithm\": algorithm,\n",
    "                }\n",
    "                test_error_df_list.append(pd.DataFrame(test_error_dict, index=[0]))\n",
    "        my_combined_results_df = pd.concat(test_error_df_list).reset_index()\n",
    "    return my_combined_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# date_time = \"2023-03-06_17:34\"\n",
    "# date_time = \"2023-03-22_17:46\"\n",
    "# date_time = \"2023-03-22_18:45\"\n",
    "# date_time = \"2023-03-22_19:15\"\n",
    "# date_time = \"2023-04-03_18:15\"\n",
    "# date_time = \"2023-04-03_18:31\"\n",
    "date_time = \"2023-03-22_18:12\"\n",
    "date_time = \"2023-03-22_19:01\"\n",
    "date_time = \"2023-04-10_11:18\"\n",
    "date_time = \"2023-04-10_12:28\"\n",
    "\n",
    "# date_time = \"2023-04-10_17:47\"\n",
    "date_time = \"2023-04-10_15:31\"\n",
    "date_time = \"2023-05-29_12:40\"\n",
    "date_time = \"2023-06-21_17:26\"\n",
    "date_time = \"2023-06-21_19:01\"\n",
    "date_time = \"2023-06-28_13:01\"\n",
    "# date_time = \"2023-07-19_20:27\"\n",
    "date_time = \"2023-07-20_16:36\"\n",
    "\n",
    "# NECROMASS DF\n",
    "# date_time = \"2023-07-20_16:44\"\n",
    "# date_time = \"2023-08-03_18:13\"\n",
    "date_time = \"2023-08-18_14:28\"\n",
    "date_time = \"2023-08-18_14:28\"\n",
    "date_time = \"2023-09-15_18:01\"\n",
    "\n",
    "\n",
    "error_df = pd.read_csv(f\"{root_results_dir}/{date_time}_results.csv\")\n",
    "# error_df.loc[error_df['Algorithm'] == 'GuassianGraphicalMethod', 'Algorithm'] = 'GaussianGraphicalModel'\n",
    "\n",
    "# error_df.to_csv(f\"{root_results_dir}/{date_time}_results.csv\", index=False)\n",
    "# filter when `# of Total Samples` is 20, 40, 60, 80, 100\n",
    "# error_df = error_df[error_df[\"# of Total Samples\"].isin([10, 20, 30, 40, 50, 60])]\n",
    "\n",
    "# PLOT NECROMASS GENUS TEST ERROR GRAPH\n",
    "p9options.figure_size = (10, 6)\n",
    "categories = [\n",
    "    \"necromass_bacteria_genus\",\n",
    "    \"necromass_fungi_genus\",\n",
    "    \"necromass_bacteria_fungi_genus\",\n",
    "]\n",
    "test_error_graph(\n",
    "    error_df[error_df[\"# of Total Samples\"] <= 60], categories, name=\"necromass_genus\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necromass_bact_error_df = get_combined_error_df(\n",
    "    pd.read_csv(f\"{root_results_dir}/2023-07-20_16:44_results.csv\")\n",
    ")\n",
    "\n",
    "necromass_fungi_error_df = get_combined_error_df(\n",
    "    pd.read_csv(f\"{root_results_dir}/2023-08-03_18:13_results.csv\")\n",
    ")\n",
    "necromass_bact_plus_fungi_error_df = pd.concat(\n",
    "    [necromass_bact_error_df, necromass_fungi_error_df]\n",
    ")\n",
    "\n",
    "\n",
    "necromass_bact_fungi_combined_error_df = get_combined_error_df(\n",
    "    pd.read_csv(f\"{root_results_dir}/2023-08-18_14:28_results.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "necromass_bact_error_df = get_combined_error_df(\n",
    "    pd.read_csv(f\"{root_results_dir}/2023-07-20_16:44_results.csv\")\n",
    ")\n",
    "\n",
    "necromass_fungi_error_df = get_combined_error_df(\n",
    "    pd.read_csv(f\"{root_results_dir}/2023-08-03_18:13_results.csv\")\n",
    ")\n",
    "necromass_bact_plus_fungi_error_df = pd.concat(\n",
    "    [necromass_bact_error_df, necromass_fungi_error_df]\n",
    ")\n",
    "\n",
    "\n",
    "necromass_bact_fungi_combined_error_df = get_combined_error_df(\n",
    "    pd.read_csv(f\"{root_results_dir}/2023-08-18_14:28_results.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necromass_bact_plus_fungi_error_df = pd.concat(\n",
    "#     [necromass_bact_error_df, necromass_fungi_error_df]\n",
    "# )\n",
    "\n",
    "test_error_df_list = []\n",
    "\n",
    "n_samples_list = (\n",
    "    necromass_bact_plus_fungi_error_df[\"# of Total Samples\"].unique().tolist()\n",
    ")\n",
    "for n_sample in n_samples_list:\n",
    "    filtered_necromass_bact_plus_fungi_error_df = necromass_bact_plus_fungi_error_df[\n",
    "        necromass_bact_plus_fungi_error_df[\"# of Total Samples\"] == n_sample\n",
    "    ]\n",
    "    filtered_necromass_bact_fungi_combined_error_df = (\n",
    "        necromass_bact_fungi_combined_error_df[\n",
    "            necromass_bact_fungi_combined_error_df[\"# of Total Samples\"] == n_sample\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    custom_bact_fungi_sum_mse = filtered_necromass_bact_plus_fungi_error_df[\n",
    "        \"Mean Squared Error\"\n",
    "    ].sum()\n",
    "    custom_bact_fungi_std_mse = filtered_necromass_bact_plus_fungi_error_df[\n",
    "        \"Mean Squared Error\"\n",
    "    ].std()\n",
    "\n",
    "    bact_fungi_sum_mse = filtered_necromass_bact_fungi_combined_error_df[\n",
    "        \"Mean Squared Error\"\n",
    "    ].sum()\n",
    "    bact_fungi_std_mse = filtered_necromass_bact_fungi_combined_error_df[\n",
    "        \"Mean Squared Error\"\n",
    "    ].std()\n",
    "\n",
    "    test_error_df_list.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"# of Total Samples\": n_sample,\n",
    "                \"Total Sum of Error\": custom_bact_fungi_sum_mse,\n",
    "                \"ymin\": custom_bact_fungi_sum_mse - custom_bact_fungi_std_mse,\n",
    "                \"ymax\": custom_bact_fungi_sum_mse + custom_bact_fungi_std_mse,\n",
    "                \"Dataset\": \"Bacteria + Fungi\",\n",
    "            },\n",
    "            index=[0],\n",
    "        )\n",
    "    )\n",
    "\n",
    "    test_error_df_list.append(\n",
    "        pd.DataFrame(\n",
    "            {\n",
    "                \"# of Total Samples\": n_sample,\n",
    "                \"Total Sum of Error\": bact_fungi_sum_mse,\n",
    "                \"ymin\": bact_fungi_sum_mse - bact_fungi_std_mse,\n",
    "                \"ymax\": bact_fungi_sum_mse + bact_fungi_std_mse,\n",
    "                \"Dataset\": \"Bacteria_Fungi_Combined\",\n",
    "            },\n",
    "            index=[0],\n",
    "        )\n",
    "    )\n",
    "\n",
    "my_combined_results_df = pd.concat(test_error_df_list).reset_index()\n",
    "\n",
    "\n",
    "# Create a line plot with ribbon variation using plotnine\n",
    "gg = (\n",
    "    p9.ggplot(my_combined_results_df)\n",
    "    + p9.aes(\n",
    "        x=\"# of Total Samples\",\n",
    "        y=\"Total Sum of Error\",\n",
    "        ymin=\"ymin\",\n",
    "        ymax=\"ymax\",\n",
    "        fill=\"Dataset\",\n",
    "    )  # Add fill argument\n",
    "    + p9.geom_line(p9.aes(color=\"Dataset\"))\n",
    "    + p9.geom_ribbon(alpha=0.3)  # Add color argument\n",
    "    + p9.scale_color_manual(values=[\"blue\", \"red\"])\n",
    "    + p9.scale_fill_manual(values=[\"blue\", \"red\"])\n",
    "    + p9.scale_x_continuous(breaks=n_samples_list)\n",
    "    + p9.xlab(\"# of Total Samples\")\n",
    ")\n",
    "\n",
    "print(gg)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "6c51af742e141fb8ae370995bc6149e53fca1868e122616bc9da9e07ef681ffa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
