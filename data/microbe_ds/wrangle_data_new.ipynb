{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "CV = 5\n",
    "TOP_COLS = 30 - 1\n",
    "TOP_GRPS = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## HMPv13_otu_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Project ID : 1928\n",
    "# Subject ID: SRS \n",
    "# Experiment ID: SRX\n",
    "# Run ID: SRR\n",
    "\n",
    "# df = pd.read_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/HMPv13_otu_table.csv').T\n",
    "df = pd.read_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/HMPv35_otu_table.csv').T\n",
    "# Convert the index to a series and split it\n",
    "id_df = df.index.to_series().str.split('.', expand=True)\n",
    "# Rename the columns as per your requirement\n",
    "id_df.columns = ['Project_ID', 'SRS_ID', 'SRX_ID', 'SRR_ID']\n",
    "# Now 'id_df' has the separate columns. You can join this back to your original DataFrame if needed\n",
    "# join infront of the df\n",
    "df = df.join(id_df).reset_index(drop=True)\n",
    "df = df.sort_values('SRX_ID')\n",
    "# drop the columns that are not needed\n",
    "df = df.drop(['Project_ID', 'SRS_ID', 'SRR_ID'], axis=1)\n",
    "# rename the SRX_ID column to Sample_ID\n",
    "df = df.rename(columns={'SRX_ID': 'Group_ID'}).reset_index(drop=True)\n",
    "\n",
    "# give the group ID a number each\n",
    "df['Group_ID'] = (pd.factorize(df['Group_ID'])[0] + 1)\n",
    "\n",
    "# drop the Group_ID column\n",
    "# df = df.drop(['Group_ID'], axis=1)\n",
    "# df = np.log(df + 1)\n",
    "# df.to_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/HMPv13_otu_table_log.csv')\n",
    "\n",
    "df['Group_ID'] = df['Group_ID'].astype(int)\n",
    "df\n",
    "\n",
    "# df_selected is without the Group_ID column\n",
    "df_selected = df.drop(['Group_ID'], axis=1) \n",
    "df_selected = np.log10(df_selected + 1)\n",
    "df_selected['Group_ID'] = df['Group_ID']\n",
    "df_selected\n",
    "\n",
    "# First, find the minimum group size\n",
    "min_group_size = int(df_selected['Group_ID'].value_counts().mean())\n",
    "\n",
    "# but min_group_size should be a multiple of the cv constant which is 5\n",
    "min_group_size = min_group_size - (min_group_size % CV)\n",
    "\n",
    "# remove all groups that are smaller than the min_group_size\n",
    "df_selected = df_selected.groupby('Group_ID').filter(lambda x: len(x) >= min_group_size)\n",
    "\n",
    "# Now, use groupby and sample to get equal-sized samples from each group\n",
    "equal_samples_df = df_selected.groupby('Group_ID').apply(lambda x: x.sample(min_group_size)).reset_index(drop=True)\n",
    "\n",
    "# arrange Group_ID in ascending order\n",
    "equal_samples_df = equal_samples_df.sort_values('Group_ID').reset_index(drop=True)\n",
    "equal_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# equal_samples_df.to_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/HMPv13_sub_log_update.csv', index=False)\n",
    "equal_samples_df.to_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/HMPv35_sub_log_update.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read and transform the data\n",
    "df = pd.read_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/HMPv35_otu_table.csv').T\n",
    "\n",
    "# Process IDs\n",
    "id_df = df.index.to_series().str.split('.', expand=True)\n",
    "id_df.columns = ['Project_ID', 'SRS_ID', 'SRX_ID', 'SRR_ID']\n",
    "df = df.join(id_df).reset_index(drop=True)\n",
    "df = df.sort_values('SRX_ID')\n",
    "df = df.drop(['Project_ID', 'SRS_ID', 'SRR_ID'], axis=1)\n",
    "df = df.rename(columns={'SRX_ID': 'Group_ID'}).reset_index(drop=True)\n",
    "df['Group_ID'] = (pd.factorize(df['Group_ID'])[0] + 1)\n",
    "\n",
    "# Convert Group_ID to int and filter by TOP_GRPS\n",
    "df['Group_ID'] = df['Group_ID'].astype(int)\n",
    "\n",
    "\n",
    "def filter_informative_columns(df, zero_threshold=0.6, n_top_columns=30):\n",
    "    \"\"\"\n",
    "    Filter columns based on:\n",
    "    1. Percentage of zero entries (remove if too many zeros)\n",
    "    2. Sort by non-zero entries and take top columns\n",
    "    \n",
    "    Parameters:\n",
    "    - df: DataFrame\n",
    "    - zero_threshold: maximum allowed fraction of zeros (default 0.8)\n",
    "    - n_top_columns: number of top columns to select (default 20)\n",
    "    \n",
    "    Returns:\n",
    "    - DataFrame with filtered columns\n",
    "    \"\"\"\n",
    "    # Separate Group_ID\n",
    "    group_id = df['Group_ID']\n",
    "    data_cols = df.drop('Group_ID', axis=1)\n",
    "    \n",
    "    # Calculate fraction of zeros in each column\n",
    "    zero_fractions = (data_cols == 0).mean()\n",
    "    \n",
    "    # Get columns that pass the zero threshold\n",
    "    mask = (zero_fractions < zero_threshold)\n",
    "    \n",
    "    # Sort columns by non-zero fraction and take top n\n",
    "    scores = (1 - zero_fractions[mask])\n",
    "    top_cols = scores.sort_values(ascending=False).head(n_top_columns).index\n",
    "    \n",
    "    # Create final DataFrame\n",
    "    df_filtered = data_cols[top_cols]\n",
    "    df_filtered = np.log10(df_filtered + 1)\n",
    "    df_filtered['Group_ID'] = group_id\n",
    "    \n",
    "    # Print some information about the filtering\n",
    "    print(f\"Original number of columns: {len(data_cols.columns)}\")\n",
    "    print(f\"Columns after zero threshold: {len(scores)}\")\n",
    "    print(f\"Final number of columns: {len(top_cols)}\")\n",
    "    \n",
    "    return df_filtered\n",
    "\n",
    "# Apply the filtering\n",
    "df_selected = filter_informative_columns(df)\n",
    "\n",
    "# First, find the minimum group size\n",
    "min_group_size = int(df_selected['Group_ID'].value_counts().mean())\n",
    "\n",
    "# but min_group_size should be a multiple of the cv constant which is 5\n",
    "min_group_size = min_group_size - (min_group_size % CV)\n",
    "\n",
    "# remove all groups that are smaller than the min_group_size\n",
    "df_selected = df_selected.groupby('Group_ID').filter(lambda x: len(x) >= min_group_size)\n",
    "\n",
    "# Now, use groupby and sample to get equal-sized samples from each group\n",
    "equal_samples_df = df_selected.groupby('Group_ID').apply(lambda x: x.sample(min_group_size)).reset_index(drop=True)\n",
    "\n",
    "# arrange Group_ID in ascending order\n",
    "equal_samples_df = equal_samples_df.sort_values('Group_ID').reset_index(drop=True)\n",
    "\n",
    "# Calculate group sparsity and select top groups based on least sparse groups\n",
    "group_sparsity = equal_samples_df.groupby('Group_ID').apply(\n",
    "    lambda x: (x.drop('Group_ID', axis=1) == 0).mean().mean()\n",
    ").sort_values()  # Sort groups by their sparsity\n",
    "\n",
    "# Take the top N least sparse groups\n",
    "top_groups = group_sparsity.head(TOP_GRPS).index\n",
    "equal_samples_df = equal_samples_df[equal_samples_df['Group_ID'].isin(top_groups)]\n",
    "equal_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_samples_df.to_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/HMPv35_filtered.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_samples_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MovingPictures_otu_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/MovingPictures_otu_table.csv').T\n",
    "id_df = df.index.to_series().str.split('.', expand=True)\n",
    "id_df.columns = ['Project_ID', 'Sample_ID', 'S_Constant', 'Group_ID', 'Sequence_Keyword']\n",
    "df = df.join(id_df).reset_index(drop=True)\n",
    "df = df.sort_values('Group_ID')\n",
    "df = df.drop(['Project_ID', 'Sample_ID', 'S_Constant', 'Sequence_Keyword'], axis=1).reset_index(drop=True)\n",
    "\n",
    "# drop the Group_ID column\n",
    "# df = df.drop(['Group_ID'], axis=1)\n",
    "# df = np.log(df + 1)\n",
    "# df.to_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/MovingPictures_otu_table_log.csv')\n",
    "# df\n",
    "\n",
    "df['Group_ID'] = (pd.factorize(df['Group_ID'])[0] + 1)\n",
    "df['Group_ID'] = df['Group_ID'].astype(int)\n",
    "\n",
    "# df_selected is without the Group_ID column\n",
    "df_selected = df.drop(['Group_ID'], axis=1) \n",
    "df_selected = np.log10(df_selected + 1)\n",
    "df_selected['Group_ID'] = df['Group_ID']\n",
    "df_selected\n",
    "\n",
    "# column_sums = df.sum(axis=0).sort_values(ascending=False)\n",
    "# top_20_columns = column_sums.head(TOP_COLS).index\n",
    "# df_selected = df[top_20_columns]\n",
    "# df_selected = np.log10(df_selected + 1)\n",
    "# df_selected['Group_ID'] = df['Group_ID']\n",
    "\n",
    "# First, find the minimum group size\n",
    "min_group_size = int(df_selected['Group_ID'].value_counts().mean())\n",
    "\n",
    "# but min_group_size should be a multiple of the cv constant which is 5\n",
    "min_group_size = min_group_size - (min_group_size % CV)\n",
    "\n",
    "# remove all groups that are smaller than the min_group_size\n",
    "df_selected = df_selected.groupby('Group_ID').filter(lambda x: len(x) >= min_group_size)\n",
    "\n",
    "# Now, use groupby and sample to get equal-sized samples from each group\n",
    "equal_samples_df = df_selected.groupby('Group_ID').apply(lambda x: x.sample(min_group_size)).reset_index(drop=True)\n",
    "\n",
    "# arrange Group_ID in ascending order\n",
    "equal_samples_df = equal_samples_df.sort_values('Group_ID').reset_index(drop=True)\n",
    "equal_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_samples_df.to_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/MovingPictures_sub_log_update.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## qa10394_otu_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/qa10394_otu_table.csv').T\n",
    "id_df = df.index.to_series().str.split('.', expand=True)\n",
    "# use only column with index 1\n",
    "id_df = id_df.iloc[:, 1]\n",
    "id_df = id_df.rename('Group_ID')\n",
    "df = df.join(id_df).reset_index(drop=True)\n",
    "df = df.sort_values('Group_ID')\n",
    "df = df[(df.Group_ID != \"BLANK\") & (df.Group_ID != \"mistake\")]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "\n",
    "# drop the Group_ID column\n",
    "#df = df.drop(['Group_ID'], axis=1)\n",
    "#df = np.log(df + 1)\n",
    "#df.to_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/qa10394_otu_table_log.csv')\n",
    "\n",
    "df['Group_ID'] = (pd.factorize(df['Group_ID'])[0] + 1)\n",
    "df['Group_ID'] = df['Group_ID'].astype(int)\n",
    "\n",
    "# df_selected is without the Group_ID column\n",
    "df_selected = df.drop(['Group_ID'], axis=1) \n",
    "df_selected = np.log10(df_selected + 1)\n",
    "df_selected['Group_ID'] = df['Group_ID']\n",
    "df_selected\n",
    "\n",
    "# First, find the minimum group size\n",
    "min_group_size = int(df_selected['Group_ID'].value_counts().mean())\n",
    "\n",
    "# but min_group_size should be a multiple of the cv constant which is 5\n",
    "min_group_size = min_group_size - (min_group_size % CV)\n",
    "\n",
    "# remove all groups that are smaller than the min_group_size\n",
    "df_selected = df_selected.groupby('Group_ID').filter(lambda x: len(x) >= min_group_size)\n",
    "\n",
    "# Now, use groupby and sample to get equal-sized samples from each group\n",
    "equal_samples_df = df_selected.groupby('Group_ID').apply(lambda x: x.sample(min_group_size)).reset_index(drop=True)\n",
    "\n",
    "# arrange Group_ID in ascending order\n",
    "equal_samples_df = equal_samples_df.sort_values('Group_ID').reset_index(drop=True)\n",
    "equal_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_samples_df.to_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/qa10394_sub_log_update.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TwinsUK_otu_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/TwinsUK_otu_table.csv').T\n",
    "id_df = df.index.to_series().str.split('.', expand=True)\n",
    "id_df = id_df.iloc[:, 1]\n",
    "id_df = id_df.rename('Group_ID')\n",
    "df = df.join(id_df).reset_index(drop=True)\n",
    "df = df.sort_values('Group_ID').reset_index(drop=True)\n",
    "\n",
    "\n",
    "# drop the Group_ID column\n",
    "#df = df.drop(['Group_ID'], axis=1)\n",
    "#df = np.log(df + 1)\n",
    "#df.to_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/TwinsUK_otu_table_log.csv')\n",
    "df['Group_ID'] = (pd.factorize(df['Group_ID'])[0] + 1)\n",
    "df['Group_ID'] = df['Group_ID'].astype(int)\n",
    "\n",
    "# df_selected is without the Group_ID column\n",
    "df_selected = df.drop(['Group_ID'], axis=1) \n",
    "df_selected = np.log10(df_selected + 1)\n",
    "df_selected['Group_ID'] = df['Group_ID']\n",
    "# df_selected\n",
    "\n",
    "# First, find the minimum group size\n",
    "min_group_size = int(df_selected['Group_ID'].value_counts().mean())\n",
    "\n",
    "# but min_group_size should be a multiple of the cv constant which is 5\n",
    "min_group_size = min_group_size - (min_group_size % CV)\n",
    "\n",
    "# remove all groups that are smaller than the min_group_size\n",
    "df_selected = df_selected.groupby('Group_ID').filter(lambda x: len(x) >= min_group_size)\n",
    "\n",
    "# Now, use groupby and sample to get equal-sized samples from each group\n",
    "equal_samples_df = df_selected.groupby('Group_ID').apply(lambda x: x.sample(min_group_size)).reset_index(drop=True)\n",
    "\n",
    "# arrange Group_ID in ascending order\n",
    "equal_samples_df = equal_samples_df.sort_values('Group_ID').reset_index(drop=True)\n",
    "equal_samples_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "equal_samples_df.to_csv('/projects/genomic-ml/da2343/ml_project_1/data/microbe_ds/TwinsUK_sub_log_update.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
