{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import *\n",
    "sys.path.append(os.path.abspath(\"/projects/genomic-ml/da2343/ml_project_1/shared\"))\n",
    "from model_header import *\n",
    "from constants import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "params_df = pd.read_csv(\"params.csv\")\n",
    "if len(sys.argv) == 2:\n",
    "    prog_name, task_str = sys.argv\n",
    "    param_row = int(task_str)\n",
    "else:\n",
    "    print(\"len(sys.argv)=%d so trying first param\" % len(sys.argv))\n",
    "    param_row = 0\n",
    "    \n",
    "param_dict = dict(params_df.iloc[param_row, :])\n",
    "data_set_name = param_dict[\"Dataset\"]\n",
    "index_of_pred_col = param_dict[\"Index of Prediction Col\"]\n",
    "\n",
    "\n",
    "dataset_path = dataset_dict[data_set_name]\n",
    "n_splits = 3\n",
    "\n",
    "# Import the csv file of the dataset\n",
    "dataset_pd = pd.read_csv(dataset_path, header=0)\n",
    "col_names = list(dataset_pd.columns)\n",
    "# drop only one column per every iteration to form the input matrix\n",
    "# make the column you removed the output\n",
    "# print the size of the input matrix\n",
    "output_vec = dataset_pd.iloc[:, index_of_pred_col].to_frame().to_numpy().ravel()\n",
    "input_mat = dataset_pd.drop( dataset_pd.columns[index_of_pred_col], axis=1).to_numpy()\n",
    "\n",
    "\n",
    "# threshold_param_list = np.concatenate(\n",
    "#     (np.linspace(0, 0.2, 125), np.linspace(0.21, 0.4, 21), np.arange(0.5, 1.01, 0.1)))\n",
    "# threshold_param_list = np.concatenate((np.linspace(0, 0.4, 5), \n",
    "#      np.linspace(0.41, 0.6, 21), np.arange(0.7, 1.01, 0.1)))\n",
    "threshold_param_list = np.arange(0, 1.01, 0.1)\n",
    "threshold_param_dict = [{'threshold': [threshold]}\n",
    "                        for threshold in threshold_param_list]\n",
    "\n",
    "# alpha_param_list = [10 ** x for x in np.concatenate((np.arange(-7, -2.5, 1), \n",
    "#                                        np.linspace(-2.5, -0.01, 50), \n",
    "#                                        np.arange(0, 1, 0.5)))]\n",
    "alpha_param_list = [10 ** x for x in range(-10, 2)]\n",
    "alpha_param_dict = [{'alpha': [alpha]} for alpha in alpha_param_list]\n",
    "\n",
    "\n",
    "my_algorithm_list = [\n",
    "   {\n",
    "        'learner': GridSearchCV(MyPearsonRegressor(),\n",
    "                                threshold_param_dict,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                return_train_score=True),\n",
    "        'reg_param': 'threshold',\n",
    "        'name': 'Pearson',\n",
    "    },\n",
    "    {\n",
    "        'learner': GridSearchCV(SpearmanRankRegressor(),\n",
    "                                threshold_param_dict,\n",
    "                                scoring='neg_mean_squared_error',\n",
    "                                return_train_score=True),\n",
    "        'reg_param': 'threshold',\n",
    "        'name': 'Spearman',\n",
    "    },\n",
    "    {\n",
    "        'learner': GaussianGraphicalModel(),\n",
    "        'reg_param': 'alpha',\n",
    "        'name': 'GGM',\n",
    "    },\n",
    "    {\n",
    "        'learner': GridSearchCV(Lasso(), \n",
    "                                alpha_param_dict,\n",
    "                                scoring='neg_mean_squared_error', \n",
    "                                return_train_score=True),\n",
    "        'reg_param': 'alpha',\n",
    "        'name': 'LASSO',\n",
    "    },\n",
    "]\n",
    "\n",
    "lasso_coef_df_list = []\n",
    "pearson_mc_df_list = []\n",
    "source_target_df_list = []\n",
    "\n",
    "pearson_source_target_df_list = []\n",
    "spearman_source_target_df_list = []\n",
    "ggm_source_target_df_list = []\n",
    "\n",
    "\n",
    "k_fold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "for fold_id, indices in enumerate(k_fold.split(input_mat)):\n",
    "    index_dict = dict(zip([\"train\", \"test\"], indices))\n",
    "    set_data_dict = {}\n",
    "    for set_name, index_vec in index_dict.items():\n",
    "        set_data_dict[set_name] = {\n",
    "            \"X\": input_mat[index_vec],\n",
    "            \"y\": output_vec[index_vec]\n",
    "        }\n",
    "\n",
    "    for algorithm_dict in my_algorithm_list:\n",
    "        my_learner = algorithm_dict[\"learner\"]\n",
    "        my_reg_param = algorithm_dict[\"reg_param\"]\n",
    "        my_algo_name = algorithm_dict[\"name\"]\n",
    "\n",
    "        my_learner.fit(**set_data_dict[\"train\"])\n",
    "        X_train = set_data_dict[\"train\"][\"X\"]\n",
    "        y_train = set_data_dict[\"train\"][\"y\"]\n",
    "        X_train_ranked = ss.rankdata(X_train, axis=0)\n",
    "        y_train_ranked = ss.rankdata(y_train)\n",
    "        \n",
    "\n",
    "        if my_algo_name == 'LASSO':\n",
    "            hyperparam_list = my_learner.cv_results_['params']\n",
    "            mean_train_score_list = my_learner.cv_results_['mean_train_score'] * -1\n",
    "            mean_test_score_list = my_learner.cv_results_['mean_test_score'] * -1\n",
    "            \n",
    "            lasso_mc_df_list = []\n",
    "            estimator = Lasso()\n",
    "            for hyperparam in hyperparam_list:\n",
    "                estimator.set_params(**hyperparam)\n",
    "                estimator.fit(**set_data_dict[\"train\"])\n",
    "                coef_list = estimator.coef_.tolist()\n",
    "                coef_list.insert(index_of_pred_col, None)\n",
    "                coef_array = np.array(coef_list)\n",
    "                score_index = hyperparam_list.index(hyperparam)\n",
    "                lasso_mc_df_list.append(\n",
    "                    {\n",
    "                        'subtrain_score': mean_train_score_list[score_index],\n",
    "                        'validation_score': mean_test_score_list[score_index],\n",
    "                        'reg_param': hyperparam['alpha'],\n",
    "                        'algorithm': my_algo_name,\n",
    "                        'data_set_name': data_set_name,\n",
    "                        'fold_id': fold_id,\n",
    "                        'index_of_pred_col': index_of_pred_col,\n",
    "                        'coefs': coef_array,\n",
    "                    }\n",
    "                ) \n",
    "            lasso_coef_df_list.append(pd.DataFrame(lasso_mc_df_list))\n",
    "\n",
    "final_pearson_corr_df = pd.concat(pearson_mc_df_list)\n",
    "final_lasso_coef_df = pd.concat(lasso_coef_df_list)\n",
    "final_pearson_source_target_df = pd.concat(pearson_source_target_df_list)\n",
    "final_spearman_source_target_df = pd.concat(spearman_source_target_df_list)\n",
    "\n",
    "if index_of_pred_col == 0:\n",
    "    final_ggm_source_target_df = pd.concat(ggm_source_target_df_list)\n",
    "    final_ggm_source_target_df.to_csv(f\"ggm_source_target/{param_row}.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "# Save dataframe as a csv to output directory\n",
    "# print(main_test_df)\n",
    "# main_test_df.to_csv(f\"results/{param_row}.csv\", encoding='utf-8', index=False)\n",
    "# final_lasso_coef_df.to_csv(f\"lasso_coef/{param_row}.csv\", encoding='utf-8', index=False)\n",
    "# final_pearson_corr_df.to_csv(f\"pearson_corr/{param_row}.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "# final_pearson_source_target_df.to_csv(f\"pearson_source_target/{param_row}.csv\", encoding='utf-8', index=False)\n",
    "# final_spearman_source_target_df.to_csv(f\"spearman_source_target/{param_row}.csv\", encoding='utf-8', index=False)\n",
    "# print(\"Done!!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello worldhello worldhello worldhello world\n",
      "\n",
      "\n",
      "\n",
      "Multiprocessing result: [5525, 42925, 140906375, 338350]\n",
      "Multiprocessing time: 0.012546062469482422\n"
     ]
    }
   ],
   "source": [
    "# Import the modules\n",
    "import time\n",
    "import multiprocessing\n",
    "import threading\n",
    "\n",
    "global_var = \"hello world\"\n",
    "# Define the function to calculate the sum of squares\n",
    "def sum_squares(n):\n",
    "    s = 0\n",
    "    print(global_var)\n",
    "    for i in range(1, n+1):\n",
    "        s += i*i\n",
    "    return s\n",
    "\n",
    "# Define the number of processes or threads to use\n",
    "num_workers = 9\n",
    "\n",
    "# Define the range of numbers to calculate\n",
    "num_range = [25, 50, 750, 100]\n",
    "\n",
    "# Define the multiprocessing function\n",
    "def multiprocessing_func():\n",
    "    # Create a pool of processes\n",
    "    pool = multiprocessing.Pool(num_workers)\n",
    "    # Start the timer\n",
    "    start_time = time.time()\n",
    "    # Map the function to the range of numbers\n",
    "    result = pool.map(sum_squares, num_range)\n",
    "    # Close the pool\n",
    "    pool.close()\n",
    "    # Join the processes\n",
    "    pool.join()\n",
    "    # Stop the timer\n",
    "    end_time = time.time()\n",
    "    # Print the result and the time taken\n",
    "    print(f\"Multiprocessing result: {result}\")\n",
    "    print(f\"Multiprocessing time: {end_time - start_time}\")\n",
    "\n",
    "# Run the multiprocessing function\n",
    "multiprocessing_func()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_selection_params(index_of_pred_col):\n",
    "    input_mat, output_vec = prep_data(dataset_pd, index_of_pred_col)\n",
    "    set_data_dict = {}\n",
    "    for set_name, index_vec in index_dict.items():\n",
    "        set_data_dict[set_name] = {\n",
    "            \"X\": input_mat[index_vec],\n",
    "            \"y\": output_vec[index_vec]\n",
    "        }\n",
    "    my_learner = GridSearchCV(MyPearsonRegressor(),\n",
    "                        threshold_param_dict,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                        return_train_score=True)\n",
    "    my_learner.fit(**set_data_dict[\"train\"])\n",
    "    X_train = set_data_dict[\"train\"][\"X\"]\n",
    "    y_train = set_data_dict[\"train\"][\"y\"]\n",
    "    params_list = get_corr_hyper_params(X = X_train, \n",
    "                                        y = y_train, \n",
    "                                        cv_results = my_learner.cv_results_)\n",
    "    pearson_mc_df = pd.DataFrame(params_list)\n",
    "    # rename the column name threshold to reg_param\n",
    "    pearson_mc_df.rename(columns={my_reg_param: 'reg_param'}, inplace=True)\n",
    "    pearson_mc_df['subtrain_score'] = my_learner.cv_results_['mean_train_score'] * -1\n",
    "    pearson_mc_df['validation_score'] = my_learner.cv_results_['mean_test_score'] * -1\n",
    "    pearson_mc_df['index_of_pred_col'] = index_of_pred_col      \n",
    "    return pearson_mc_df  \n",
    "\n",
    "num_workers = 9\n",
    "\n",
    "index_of_pred_col_range = list(range(0, 10))\n",
    "# Define the multiprocessing function\n",
    "def multiprocessing_func():\n",
    "    # Create a pool of processes\n",
    "    pool = multiprocessing.Pool(num_workers)\n",
    "    # Map the function to the range of numbers\n",
    "    result = pool.map(get_model_selection_params, index_of_pred_col_range)\n",
    "    pool.close()\n",
    "    pool.join()\n",
    "    # Print the result and the time taken\n",
    "    print(f\"Multiprocessing result: {result}\")\n",
    "\n",
    "# Run the multiprocessing function\n",
    "multiprocessing_func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             coefs\n",
      "0  [1, 2, 3, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "# Import pandas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "my_list = []\n",
    "coef_list = [1, 2, 3, 4, 5]\n",
    "coef_array = np.array(coef_list)\n",
    "my_list.append(\n",
    "    {\n",
    "        'coefs': coef_array,\n",
    "    }\n",
    ")\n",
    "\n",
    "df = pd.DataFrame(my_list)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             coefs  index_of_pred_col\n",
      "0  [1, 2, 3, 4, 5]                  0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame(\n",
    "    {'coefs': [np.array([1, 2, 3, 4, 5])],\n",
    "     'index_of_pred_col': [0]\n",
    "        }\n",
    "    )\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import Lasso\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import *\n",
    "sys.path.append(os.path.abspath(\"/projects/genomic-ml/da2343/ml_project_1/shared\"))\n",
    "from model_header import *\n",
    "from constants import *\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "\n",
    "params_df = pd.read_csv(\"params.csv\")\n",
    "if len(sys.argv) == 2:\n",
    "    prog_name, task_str = sys.argv\n",
    "    param_row = int(task_str)\n",
    "else:\n",
    "    print(\"len(sys.argv)=%d so trying first param\" % len(sys.argv))\n",
    "    param_row = 0\n",
    "    \n",
    "param_dict = dict(params_df.iloc[param_row, :])\n",
    "data_set_name = param_dict[\"Dataset\"]\n",
    "index_of_pred_col = param_dict[\"Index of Prediction Col\"]\n",
    "\n",
    "\n",
    "dataset_path = dataset_dict[data_set_name]\n",
    "n_splits = 3\n",
    "\n",
    "# Import the csv file of the dataset\n",
    "dataset_pd = pd.read_csv(dataset_path, header=0)\n",
    "col_names = list(dataset_pd.columns)\n",
    "# drop only one column per every iteration to form the input matrix\n",
    "# make the column you removed the output\n",
    "# print the size of the input matrix\n",
    "output_vec = dataset_pd.iloc[:, index_of_pred_col].to_frame().to_numpy().ravel()\n",
    "input_mat = dataset_pd.drop( dataset_pd.columns[index_of_pred_col], axis=1).to_numpy()\n",
    "\n",
    "\n",
    "threshold_param_list = np.arange(0, 1.01, 0.1)\n",
    "threshold_param_dict = [{'threshold': [threshold]}\n",
    "                        for threshold in threshold_param_list]\n",
    "\n",
    "lasso_coef_df_list = []\n",
    "pearson_mc_df_list = []\n",
    "source_target_df_list = []\n",
    "\n",
    "pearson_source_target_df_list = []\n",
    "spearman_source_target_df_list = []\n",
    "\n",
    "\n",
    "my_learner = GridSearchCV(MyPearsonRegressor(),\n",
    "                        threshold_param_dict,\n",
    "                        scoring='neg_mean_squared_error',\n",
    "                        return_train_score=True)\n",
    "my_reg_param = 'threshold'\n",
    "my_algo_name = 'Pearson'\n",
    "\n",
    "k_fold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "for fold_id, indices in enumerate(k_fold.split(input_mat)):\n",
    "    index_dict = dict(zip([\"train\", \"test\"], indices))\n",
    "    set_data_dict = {}\n",
    "    for set_name, index_vec in index_dict.items():\n",
    "        set_data_dict[set_name] = {\n",
    "            \"X\": input_mat[index_vec],\n",
    "            \"y\": output_vec[index_vec]\n",
    "        }\n",
    "\n",
    "    my_learner.fit(**set_data_dict[\"train\"])\n",
    "    X_train = set_data_dict[\"train\"][\"X\"]\n",
    "    y_train = set_data_dict[\"train\"][\"y\"]\n",
    "    params_list = get_corr_hyper_params(X = X_train, \n",
    "                                        y = y_train, \n",
    "                                        cv_results = my_learner.cv_results_)\n",
    "    pearson_mc_df = pd.DataFrame(params_list)\n",
    "    # rename the column name threshold to reg_param\n",
    "    pearson_mc_df.rename(columns={my_reg_param: 'reg_param'}, inplace=True)\n",
    "    pearson_mc_df['subtrain_score'] = my_learner.cv_results_['mean_train_score'] * -1\n",
    "    pearson_mc_df['validation_score'] = my_learner.cv_results_['mean_test_score'] * -1\n",
    "    pearson_mc_df['index_of_pred_col'] = index_of_pred_col\n",
    "    pearson_mc_df_list.append(pearson_mc_df)\n",
    "\n",
    "    # Create the source-target dataframe\n",
    "    best_reg_param = pearson_mc_df.loc[pearson_mc_df['validation_score'].idxmin(), 'reg_param']\n",
    "    source_target = get_corr_source_target(\n",
    "        X = X_train, \n",
    "        y = y_train, \n",
    "        index = index_of_pred_col,\n",
    "        threshold = best_reg_param,\n",
    "    )\n",
    "    source_target_df = pd.DataFrame(source_target, \n",
    "                                    columns=[\"source\", \"target\", \"weight\"])\n",
    "    source_target_df['fold_id'] = fold_id\n",
    "    pearson_source_target_df_list.append(source_target_df)\n",
    "    \n",
    "    \n",
    "final_pearson_corr_df = pd.concat(pearson_mc_df_list)\n",
    "final_pearson_source_target_df = pd.concat(pearson_source_target_df_list)\n",
    "\n",
    "\n",
    "# Save dataframe as a csv to output directory\n",
    "# print(main_test_df)\n",
    "# main_test_df.to_csv(f\"results/{param_row}.csv\", encoding='utf-8', index=False)\n",
    "# final_lasso_coef_df.to_csv(f\"lasso_coef/{param_row}.csv\", encoding='utf-8', index=False)\n",
    "# final_pearson_corr_df.to_csv(f\"pearson_corr/{param_row}.csv\", encoding='utf-8', index=False)\n",
    "\n",
    "# final_pearson_source_target_df.to_csv(f\"pearson_source_target/{param_row}.csv\", encoding='utf-8', index=False)\n",
    "# final_spearman_source_target_df.to_csv(f\"spearman_source_target/{param_row}.csv\", encoding='utf-8', index=False)\n",
    "# print(\"Done!!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
