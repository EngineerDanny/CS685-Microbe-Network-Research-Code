{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "sys.path.append(os.path.abspath(\"/projects/genomic-ml/da2343/ml_project_1/shared\"))\n",
    "from model_header import *\n",
    "from constants import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "params_df = pd.read_csv(\"params.csv\")\n",
    "param_row = 0\n",
    "param_dict = dict(params_df.iloc[param_row, :])\n",
    "data_set_name = param_dict[\"Dataset\"]\n",
    "n_samples = param_dict[\"# of Total Samples\"]\n",
    "index_of_pred_col = param_dict[\"Index of Prediction Col\"]\n",
    "\n",
    "dataset_path = dataset_dict[data_set_name]\n",
    "n_splits = 3\n",
    "# Import the csv file of the dataset\n",
    "df = pd.read_csv(dataset_path, header=0)\n",
    "learner_dict = {\n",
    "    \"Featureless\": Featureless(),\n",
    "    \"LassoCV\": LassoCV(random_state=1),\n",
    "}\n",
    "\n",
    "test_err_list = []\n",
    "pred_col_name = df.columns[index_of_pred_col]\n",
    "output_vec = df.iloc[:, index_of_pred_col].to_numpy().ravel()\n",
    "input_mat = df.drop(pred_col_name, axis=1).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_fold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "for fold_id, indices in enumerate(k_fold.split(input_mat)):\n",
    "    index_dict = dict(zip([\"train\", \"test\"], indices))\n",
    "    set_data_dict = {}\n",
    "    for set_name, index_vec in index_dict.items():\n",
    "        set_data_dict[set_name] = {\n",
    "            \"X\": input_mat[index_vec],\n",
    "            \"y\": output_vec[index_vec],\n",
    "        }\n",
    "    # Fit the learner to the training data\n",
    "    # Predict the test data\n",
    "    # Calculate the test error\n",
    "    for learner_name, learner in learner_dict.items():\n",
    "        learner.fit(**set_data_dict[\"train\"])\n",
    "        pred_y = learner.predict(set_data_dict[\"test\"][\"X\"])\n",
    "        actual_y = set_data_dict[\"test\"][\"y\"]\n",
    "        mse = mean_squared_error(actual_y, pred_y)\n",
    "        test_err_list.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Mean Squared Error\": mse,\n",
    "                    \"FoldID\": fold_id,\n",
    "                    \"# of Total Samples\": n_samples,\n",
    "                    \"Dataset\": data_set_name,\n",
    "                    \"Index of Predicted Column\": index_of_pred_col,\n",
    "                    \"pred_col_name\": pred_col_name,\n",
    "                    \"Algorithm\": learner_name\n",
    "                },\n",
    "                index=[0],\n",
    "            )\n",
    "        )\n",
    "test_err_df = pd.concat(test_err_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save dataframe as a csv to output directory\n",
    "out_file = f\"results/{param_row}.csv\"\n",
    "test_err_df.to_csv(out_file, encoding=\"utf-8\", index=False)\n",
    "print(\"Done!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_squared_error\n",
    "sys.path.append(os.path.abspath(\"/projects/genomic-ml/da2343/ml_project_1/shared\"))\n",
    "from model_header import *\n",
    "from constants import *\n",
    "from sklearn.dummy import *\n",
    "\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "params_df = pd.read_csv(\"params.csv\")\n",
    "param_row = 0\n",
    "param_dict = dict(params_df.iloc[param_row, :])\n",
    "data_set_name = param_dict[\"Dataset\"]\n",
    "index_of_pred_col = param_dict[\"Index of Prediction Col\"]\n",
    "\n",
    "dataset_path = dataset_dict[data_set_name]\n",
    "n_splits = 3\n",
    "# Import the csv file of the dataset\n",
    "df = pd.read_csv(dataset_path, header=0)\n",
    "reg_learner_dict = {\n",
    "    \"Featureless\": Featureless(),\n",
    "    \"LassoCV\": LassoCV(random_state=1),\n",
    "}\n",
    "classifier_dict = {\n",
    "    \"FeaturelessClassifier\": DummyClassifier(strategy=\"most_frequent\"),\n",
    "    \"LogisticRegression\": LogisticRegressionCV(random_state=1),\n",
    "}\n",
    "\n",
    "test_err_list = []\n",
    "pred_col_name = df.columns[index_of_pred_col]\n",
    "\n",
    "# two output vectors\n",
    "# one will just be the output of the regression\n",
    "output_vec_for_reg = df.iloc[:, index_of_pred_col].to_numpy().ravel()\n",
    "# the other will be the output of the binary classifier\n",
    "# when the elements in output_vec_for_reg is greater than 0 then the corresponding element in output_vec_classifier will be 1 otherwise it will be 0\n",
    "output_vec_for_class = np.where(output_vec_for_reg > 0, 1, 0)\n",
    "input_mat = df.drop(pred_col_name, axis=1).to_numpy()\n",
    "\n",
    "\n",
    "k_fold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "for fold_id, indices in enumerate(k_fold.split(input_mat)):\n",
    "    index_dict = dict(zip([\"train\", \"test\"], indices))\n",
    "    set_data_dict = {}\n",
    "    for set_name, index_vec in index_dict.items():\n",
    "        set_data_dict[set_name] = {\n",
    "            \"X\": input_mat[index_vec],\n",
    "            \"y\": output_vec_for_class[index_vec],\n",
    "        }\n",
    "    # Fit the learner to the training data\n",
    "    # Predict the test data\n",
    "    # Calculate the test error\n",
    "    for learner_name, learner in classifier_dict.items():\n",
    "        learner.fit(**set_data_dict[\"train\"])\n",
    "        pred_y = learner.predict(set_data_dict[\"test\"][\"X\"])\n",
    "        actual_y = set_data_dict[\"test\"][\"y\"]\n",
    "        accuracy = np.mean(pred_y == actual_y)\n",
    "        test_err_list.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Test Accuracy\": accuracy,\n",
    "                    \"FoldID\": fold_id,\n",
    "                    \"Dataset\": data_set_name,\n",
    "                    \"Index of Predicted Column\": pred_col_name,\n",
    "                    \"Algorithm\": learner_name\n",
    "                },\n",
    "                index=[0],\n",
    "            )\n",
    "        )\n",
    "test_err_df = pd.concat(test_err_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.model_selection import *\n",
    "from sklearn.metrics import *\n",
    "sys.path.append(os.path.abspath(\"/projects/genomic-ml/da2343/ml_project_1/shared\"))\n",
    "from model_header import *\n",
    "from constants import *\n",
    "from sklearn.dummy import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.set_printoptions(threshold=np.inf)\n",
    "params_df = pd.read_csv(\"params.csv\")\n",
    "\n",
    "# if len(sys.argv) == 2:\n",
    "#     prog_name, task_str = sys.argv\n",
    "#     param_row = int(task_str)\n",
    "# else:\n",
    "#     print(\"len(sys.argv)=%d so trying first param\" % len(sys.argv))\n",
    "#     param_row = 0\n",
    "\n",
    "param_row = 0\n",
    "param_dict = dict(params_df.iloc[param_row, :])\n",
    "data_set_name = param_dict[\"Dataset\"]\n",
    "index_of_pred_col = param_dict[\"Index of Prediction Col\"]\n",
    "\n",
    "dataset_path = dataset_dict[data_set_name]\n",
    "n_splits = 3\n",
    "# Import the csv file of the dataset\n",
    "df = pd.read_csv(dataset_path, header=0)\n",
    "\n",
    "classifier_reg_dict = {\n",
    "    \"Featureless\": {\n",
    "        \"classifier\": DummyClassifier(strategy=\"most_frequent\"),\n",
    "        \"regressor\": Featureless(),\n",
    "     },\n",
    "    \"LogisticRegLassoCV\": {\n",
    "        \"classifier\": LogisticRegressionCV(random_state=1),\n",
    "        \"regressor\": LassoCV(random_state=1),\n",
    "    }\n",
    "}    \n",
    "    \n",
    "\n",
    "test_err_list = []\n",
    "pred_col_name = df.columns[index_of_pred_col]\n",
    "\n",
    "# two output vectors\n",
    "# one will just be the output of the regression\n",
    "output_vec_for_reg = df.iloc[:, index_of_pred_col].to_numpy().ravel()\n",
    "output_vec_for_class = np.where(output_vec_for_reg > 0, 1, 0)\n",
    "input_mat = df.drop(pred_col_name, axis=1).to_numpy()\n",
    "\n",
    "\n",
    "k_fold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "for fold_id, indices in enumerate(k_fold.split(input_mat)):\n",
    "    index_dict = dict(zip([\"train\", \"test\"], indices))\n",
    "    set_data_dict = {}\n",
    "    for set_name, index_vec in index_dict.items():\n",
    "        set_data_dict[set_name] = {\n",
    "            \"X\": input_mat[index_vec],\n",
    "            \"y_class\": output_vec_for_class[index_vec],\n",
    "            \"y_reg\": output_vec_for_reg[index_vec],\n",
    "        }\n",
    "    # Fit the learner to the training data\n",
    "    # Predict the test data\n",
    "    # Calculate the test error\n",
    "    for learner_name, learner in classifier_reg_dict.items():\n",
    "        # check if y_train contains only one class\n",
    "        if len(np.unique(set_data_dict[\"train\"][\"y_class\"])) == 1:\n",
    "            # predict all test data as the class that is present in y_train\n",
    "            pred_y = np.full(set_data_dict[\"test\"][\"y_class\"].shape, \n",
    "                             np.unique(set_data_dict[\"train\"][\"y_class\"])[0])\n",
    "        else:\n",
    "            classifier = learner[\"classifier\"]\n",
    "            classifier.fit(set_data_dict[\"train\"][\"X\"], set_data_dict[\"train\"][\"y_class\"])\n",
    "            classifier_pred_y = classifier.predict(set_data_dict[\"test\"][\"X\"])\n",
    "            \n",
    "            regressor = learner[\"regressor\"]\n",
    "            regressor.fit(set_data_dict[\"train\"][\"X\"], set_data_dict[\"train\"][\"y_reg\"])\n",
    "            regressor_pred_y = regressor.predict(set_data_dict[\"test\"][\"X\"])\n",
    "            # when the classifier predicts 0 then the regressor prediction is set to 0\n",
    "            # when the classifier predicts 1 then the regressor prediction is set to the regressor prediction\n",
    "            pred_y = np.where(classifier_pred_y == 0, 0, regressor_pred_y)\n",
    "            \n",
    "        actual_y = set_data_dict[\"test\"][\"y_reg\"]\n",
    "        test_err_list.append(\n",
    "            pd.DataFrame(\n",
    "                {\n",
    "                    \"Mean Squared Error\": mean_squared_error(actual_y, pred_y),\n",
    "                    \"FoldID\": fold_id,\n",
    "                    \"Dataset\": data_set_name,\n",
    "                    \"Index of Predicted Column\": index_of_pred_col,\n",
    "                    \"Predicted Column Name\": pred_col_name,\n",
    "                    \"Algorithm\": learner_name\n",
    "                },\n",
    "                index=[0],\n",
    "            )\n",
    "        )\n",
    "test_err_df = pd.concat(test_err_list)\n",
    "# Save dataframe as a csv to output directory\n",
    "# out_file = f\"results/{param_row}.csv\"\n",
    "# test_err_df.to_csv(out_file, encoding=\"utf-8\", index=False)\n",
    "# print(\"Done!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean Squared Error</th>\n",
       "      <th>FoldID</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Index of Predicted Column</th>\n",
       "      <th>Predicted Column Name</th>\n",
       "      <th>Algorithm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.238438</td>\n",
       "      <td>0</td>\n",
       "      <td>Dec22_all_power</td>\n",
       "      <td>0</td>\n",
       "      <td>Bacillus</td>\n",
       "      <td>Featureless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.022148</td>\n",
       "      <td>0</td>\n",
       "      <td>Dec22_all_power</td>\n",
       "      <td>0</td>\n",
       "      <td>Bacillus</td>\n",
       "      <td>LogisticRegLassoCV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.964928</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec22_all_power</td>\n",
       "      <td>0</td>\n",
       "      <td>Bacillus</td>\n",
       "      <td>Featureless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.948843</td>\n",
       "      <td>1</td>\n",
       "      <td>Dec22_all_power</td>\n",
       "      <td>0</td>\n",
       "      <td>Bacillus</td>\n",
       "      <td>LogisticRegLassoCV</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.826767</td>\n",
       "      <td>2</td>\n",
       "      <td>Dec22_all_power</td>\n",
       "      <td>0</td>\n",
       "      <td>Bacillus</td>\n",
       "      <td>Featureless</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.643524</td>\n",
       "      <td>2</td>\n",
       "      <td>Dec22_all_power</td>\n",
       "      <td>0</td>\n",
       "      <td>Bacillus</td>\n",
       "      <td>LogisticRegLassoCV</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Mean Squared Error  FoldID          Dataset  Index of Predicted Column  \\\n",
       "0            1.238438       0  Dec22_all_power                          0   \n",
       "0            1.022148       0  Dec22_all_power                          0   \n",
       "0            0.964928       1  Dec22_all_power                          0   \n",
       "0            0.948843       1  Dec22_all_power                          0   \n",
       "0            0.826767       2  Dec22_all_power                          0   \n",
       "0            0.643524       2  Dec22_all_power                          0   \n",
       "\n",
       "  Predicted Column Name           Algorithm  \n",
       "0              Bacillus         Featureless  \n",
       "0              Bacillus  LogisticRegLassoCV  \n",
       "0              Bacillus         Featureless  \n",
       "0              Bacillus  LogisticRegLassoCV  \n",
       "0              Bacillus         Featureless  \n",
       "0              Bacillus  LogisticRegLassoCV  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_err_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Bacillus</th>\n",
       "      <th>Bradyrhizobium</th>\n",
       "      <th>Burkholderia</th>\n",
       "      <th>Cellvibrio</th>\n",
       "      <th>Chitinophaga</th>\n",
       "      <th>Flavobacterium</th>\n",
       "      <th>Gp16</th>\n",
       "      <th>Gp6</th>\n",
       "      <th>Kaistia</th>\n",
       "      <th>Labrys</th>\n",
       "      <th>...</th>\n",
       "      <th>Mortierella</th>\n",
       "      <th>Mucor</th>\n",
       "      <th>Ovicillium</th>\n",
       "      <th>Penicillium</th>\n",
       "      <th>Phialocephala</th>\n",
       "      <th>Russula</th>\n",
       "      <th>Tomentella</th>\n",
       "      <th>Trichoderma</th>\n",
       "      <th>Umbelopsis</th>\n",
       "      <th>Wilcoxina</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.051310</td>\n",
       "      <td>1.303894</td>\n",
       "      <td>-0.424502</td>\n",
       "      <td>-0.662478</td>\n",
       "      <td>-1.105309</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>1.026884</td>\n",
       "      <td>1.416732</td>\n",
       "      <td>-0.755748</td>\n",
       "      <td>-1.218715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.311410</td>\n",
       "      <td>-0.387194</td>\n",
       "      <td>-0.546835</td>\n",
       "      <td>1.342957</td>\n",
       "      <td>-0.155797</td>\n",
       "      <td>0.862388</td>\n",
       "      <td>0.497154</td>\n",
       "      <td>-0.207413</td>\n",
       "      <td>0.961926</td>\n",
       "      <td>-0.387296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.051310</td>\n",
       "      <td>1.268659</td>\n",
       "      <td>-1.388676</td>\n",
       "      <td>-0.662478</td>\n",
       "      <td>-1.105309</td>\n",
       "      <td>-0.212046</td>\n",
       "      <td>1.440550</td>\n",
       "      <td>1.504009</td>\n",
       "      <td>-0.755748</td>\n",
       "      <td>-0.489037</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.992687</td>\n",
       "      <td>-0.387194</td>\n",
       "      <td>-0.546835</td>\n",
       "      <td>1.583523</td>\n",
       "      <td>0.383227</td>\n",
       "      <td>1.368293</td>\n",
       "      <td>-0.752548</td>\n",
       "      <td>-1.424537</td>\n",
       "      <td>1.369599</td>\n",
       "      <td>-0.387296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.239649</td>\n",
       "      <td>1.200597</td>\n",
       "      <td>-1.388676</td>\n",
       "      <td>-0.662478</td>\n",
       "      <td>-1.105309</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>1.474802</td>\n",
       "      <td>-0.755748</td>\n",
       "      <td>-0.489037</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.208840</td>\n",
       "      <td>-0.387194</td>\n",
       "      <td>-0.546835</td>\n",
       "      <td>1.073953</td>\n",
       "      <td>-0.887091</td>\n",
       "      <td>1.253182</td>\n",
       "      <td>-1.283232</td>\n",
       "      <td>-1.424537</td>\n",
       "      <td>-0.872391</td>\n",
       "      <td>-0.387296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.408456</td>\n",
       "      <td>1.249316</td>\n",
       "      <td>0.384082</td>\n",
       "      <td>-0.662478</td>\n",
       "      <td>-1.105309</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>1.203273</td>\n",
       "      <td>1.463288</td>\n",
       "      <td>-0.755748</td>\n",
       "      <td>-1.218715</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179118</td>\n",
       "      <td>-0.387194</td>\n",
       "      <td>-0.546835</td>\n",
       "      <td>1.352706</td>\n",
       "      <td>-0.887091</td>\n",
       "      <td>1.688586</td>\n",
       "      <td>0.712848</td>\n",
       "      <td>-0.748688</td>\n",
       "      <td>1.028229</td>\n",
       "      <td>-0.387296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.340355</td>\n",
       "      <td>1.373472</td>\n",
       "      <td>-0.156500</td>\n",
       "      <td>-0.662478</td>\n",
       "      <td>-1.105309</td>\n",
       "      <td>0.137532</td>\n",
       "      <td>1.468894</td>\n",
       "      <td>1.514489</td>\n",
       "      <td>-0.755748</td>\n",
       "      <td>-0.489037</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.208840</td>\n",
       "      <td>-0.387194</td>\n",
       "      <td>-0.546835</td>\n",
       "      <td>0.813602</td>\n",
       "      <td>0.836798</td>\n",
       "      <td>1.596822</td>\n",
       "      <td>0.590149</td>\n",
       "      <td>-1.424537</td>\n",
       "      <td>0.770741</td>\n",
       "      <td>-0.387296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>-0.152223</td>\n",
       "      <td>-1.093004</td>\n",
       "      <td>1.087809</td>\n",
       "      <td>-0.662478</td>\n",
       "      <td>0.524933</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.724456</td>\n",
       "      <td>-0.705626</td>\n",
       "      <td>-0.755748</td>\n",
       "      <td>-0.118212</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.223561</td>\n",
       "      <td>-0.387194</td>\n",
       "      <td>-0.546835</td>\n",
       "      <td>-0.922557</td>\n",
       "      <td>-0.887091</td>\n",
       "      <td>-0.893952</td>\n",
       "      <td>0.781099</td>\n",
       "      <td>1.268884</td>\n",
       "      <td>-0.872391</td>\n",
       "      <td>-0.387296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>-1.493826</td>\n",
       "      <td>-0.570572</td>\n",
       "      <td>1.125368</td>\n",
       "      <td>-0.662478</td>\n",
       "      <td>0.394902</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.724456</td>\n",
       "      <td>-0.705626</td>\n",
       "      <td>-0.755748</td>\n",
       "      <td>-1.218715</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.569465</td>\n",
       "      <td>-0.387194</td>\n",
       "      <td>-0.546835</td>\n",
       "      <td>0.179539</td>\n",
       "      <td>1.413702</td>\n",
       "      <td>-0.893952</td>\n",
       "      <td>-1.283232</td>\n",
       "      <td>1.175973</td>\n",
       "      <td>-0.872391</td>\n",
       "      <td>2.567993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>-1.493826</td>\n",
       "      <td>-0.113313</td>\n",
       "      <td>1.679608</td>\n",
       "      <td>-0.662478</td>\n",
       "      <td>-0.106708</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.724456</td>\n",
       "      <td>-0.705626</td>\n",
       "      <td>-0.755748</td>\n",
       "      <td>0.713844</td>\n",
       "      <td>...</td>\n",
       "      <td>1.228625</td>\n",
       "      <td>-0.387194</td>\n",
       "      <td>-0.546835</td>\n",
       "      <td>-0.169313</td>\n",
       "      <td>1.435482</td>\n",
       "      <td>0.607643</td>\n",
       "      <td>1.415446</td>\n",
       "      <td>0.839282</td>\n",
       "      <td>-0.872391</td>\n",
       "      <td>-0.387296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>-0.459163</td>\n",
       "      <td>-1.093004</td>\n",
       "      <td>-1.388676</td>\n",
       "      <td>1.041395</td>\n",
       "      <td>-0.106708</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.724456</td>\n",
       "      <td>-0.705626</td>\n",
       "      <td>1.683835</td>\n",
       "      <td>1.160502</td>\n",
       "      <td>...</td>\n",
       "      <td>0.154034</td>\n",
       "      <td>2.431741</td>\n",
       "      <td>-0.546835</td>\n",
       "      <td>-0.922557</td>\n",
       "      <td>1.651623</td>\n",
       "      <td>0.524723</td>\n",
       "      <td>0.318935</td>\n",
       "      <td>0.617299</td>\n",
       "      <td>0.622225</td>\n",
       "      <td>-0.387296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>-1.493826</td>\n",
       "      <td>-0.113313</td>\n",
       "      <td>1.630102</td>\n",
       "      <td>-0.662478</td>\n",
       "      <td>0.910772</td>\n",
       "      <td>-0.965418</td>\n",
       "      <td>-0.724456</td>\n",
       "      <td>-0.705626</td>\n",
       "      <td>-0.755748</td>\n",
       "      <td>1.528557</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.569465</td>\n",
       "      <td>-0.387194</td>\n",
       "      <td>-0.546835</td>\n",
       "      <td>-0.922557</td>\n",
       "      <td>1.345834</td>\n",
       "      <td>-0.893952</td>\n",
       "      <td>-1.065730</td>\n",
       "      <td>1.325561</td>\n",
       "      <td>0.020225</td>\n",
       "      <td>-0.387296</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>69 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Bacillus  Bradyrhizobium  Burkholderia  Cellvibrio  Chitinophaga  \\\n",
       "0  -1.051310        1.303894     -0.424502   -0.662478     -1.105309   \n",
       "1  -1.051310        1.268659     -1.388676   -0.662478     -1.105309   \n",
       "2  -0.239649        1.200597     -1.388676   -0.662478     -1.105309   \n",
       "3   1.408456        1.249316      0.384082   -0.662478     -1.105309   \n",
       "4  -0.340355        1.373472     -0.156500   -0.662478     -1.105309   \n",
       "..       ...             ...           ...         ...           ...   \n",
       "64 -0.152223       -1.093004      1.087809   -0.662478      0.524933   \n",
       "65 -1.493826       -0.570572      1.125368   -0.662478      0.394902   \n",
       "66 -1.493826       -0.113313      1.679608   -0.662478     -0.106708   \n",
       "67 -0.459163       -1.093004     -1.388676    1.041395     -0.106708   \n",
       "68 -1.493826       -0.113313      1.630102   -0.662478      0.910772   \n",
       "\n",
       "    Flavobacterium      Gp16       Gp6   Kaistia    Labrys  ...  Mortierella  \\\n",
       "0        -0.965418  1.026884  1.416732 -0.755748 -1.218715  ...     0.311410   \n",
       "1        -0.212046  1.440550  1.504009 -0.755748 -0.489037  ...    -0.992687   \n",
       "2        -0.965418  1.380000  1.474802 -0.755748 -0.489037  ...    -1.208840   \n",
       "3        -0.965418  1.203273  1.463288 -0.755748 -1.218715  ...     0.179118   \n",
       "4         0.137532  1.468894  1.514489 -0.755748 -0.489037  ...    -1.208840   \n",
       "..             ...       ...       ...       ...       ...  ...          ...   \n",
       "64       -0.965418 -0.724456 -0.705626 -0.755748 -0.118212  ...    -0.223561   \n",
       "65       -0.965418 -0.724456 -0.705626 -0.755748 -1.218715  ...    -1.569465   \n",
       "66       -0.965418 -0.724456 -0.705626 -0.755748  0.713844  ...     1.228625   \n",
       "67       -0.965418 -0.724456 -0.705626  1.683835  1.160502  ...     0.154034   \n",
       "68       -0.965418 -0.724456 -0.705626 -0.755748  1.528557  ...    -1.569465   \n",
       "\n",
       "       Mucor  Ovicillium  Penicillium  Phialocephala   Russula  Tomentella  \\\n",
       "0  -0.387194   -0.546835     1.342957      -0.155797  0.862388    0.497154   \n",
       "1  -0.387194   -0.546835     1.583523       0.383227  1.368293   -0.752548   \n",
       "2  -0.387194   -0.546835     1.073953      -0.887091  1.253182   -1.283232   \n",
       "3  -0.387194   -0.546835     1.352706      -0.887091  1.688586    0.712848   \n",
       "4  -0.387194   -0.546835     0.813602       0.836798  1.596822    0.590149   \n",
       "..       ...         ...          ...            ...       ...         ...   \n",
       "64 -0.387194   -0.546835    -0.922557      -0.887091 -0.893952    0.781099   \n",
       "65 -0.387194   -0.546835     0.179539       1.413702 -0.893952   -1.283232   \n",
       "66 -0.387194   -0.546835    -0.169313       1.435482  0.607643    1.415446   \n",
       "67  2.431741   -0.546835    -0.922557       1.651623  0.524723    0.318935   \n",
       "68 -0.387194   -0.546835    -0.922557       1.345834 -0.893952   -1.065730   \n",
       "\n",
       "    Trichoderma  Umbelopsis  Wilcoxina  \n",
       "0     -0.207413    0.961926  -0.387296  \n",
       "1     -1.424537    1.369599  -0.387296  \n",
       "2     -1.424537   -0.872391  -0.387296  \n",
       "3     -0.748688    1.028229  -0.387296  \n",
       "4     -1.424537    0.770741  -0.387296  \n",
       "..          ...         ...        ...  \n",
       "64     1.268884   -0.872391  -0.387296  \n",
       "65     1.175973   -0.872391   2.567993  \n",
       "66     0.839282   -0.872391  -0.387296  \n",
       "67     0.617299    0.622225  -0.387296  \n",
       "68     1.325561    0.020225  -0.387296  \n",
       "\n",
       "[69 rows x 37 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs685",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
